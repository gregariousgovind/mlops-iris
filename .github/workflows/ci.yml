name: MLOps CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: true

env:
  DOCKERHUB_REPO: ${{ secrets.DOCKERHUB_USERNAME }}/mlops-iris
  PY_VERSION: "3.11"

jobs:
  # -------- Quality & Tests --------
  test:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PY_VERSION }}

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.lock.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install deps (from lock)
        run: |
          python -m pip install --upgrade pip
          test -f requirements.lock.txt || (echo "Missing requirements.lock.txt"; exit 1)
          pip install -r requirements.lock.txt

      - name: Prepare Part 1 data artifacts
        run: |
          python src/data.py
          ls -la data || true

      - name: Lint
        run: python -m flake8

      - name: Tests (with fast fail)
        run: python -m pytest -q

  # -------- Build & Push Image --------
  build-and-push:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python (for training step)
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PY_VERSION }}

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.lock.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install deps (from lock)
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.lock.txt

      - name: Prepare data & train model
        env:
          # Use local MLflow file store in CI (no server needed)
          MLFLOW_TRACKING_URI: file:./mlruns
        run: |
          python src/data.py
          python src/train.py
          test -f artifacts/model/model.joblib || (echo "Model artifact missing"; exit 1)

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Docker meta (tags & labels)
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.DOCKERHUB_REPO }}
          tags: |
            type=raw,value=latest,enable=true
            type=sha,format=short,prefix=,suffix=
          labels: |
            org.opencontainers.image.source=${{ github.repository }}
            org.opencontainers.image.revision=${{ github.sha }}

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Build & Push
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile
          platforms: linux/amd64
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Smoke test container /health
        run: |
          IMAGE_TAG=$(echo "${{ steps.meta.outputs.tags }}" | head -n1)
          echo "Testing image: $IMAGE_TAG"
          docker pull "$IMAGE_TAG"
          docker run -d --rm -p 8000:8000 --name iris-api "$IMAGE_TAG"
          for i in {1..20}; do
            sleep 1
            curl -sf http://localhost:8000/health && break || true
          done
          curl -sf http://localhost:8000/health | tee /dev/stderr
          docker stop iris-api
